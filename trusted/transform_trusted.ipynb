{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Welcome to the Glue Interactive Sessions Kernel\n",
						"For more information on available magic commands, please type %help in any new cell.\n",
						"\n",
						"Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
						"Installed kernel version: 1.0.4 \n",
						"Extra py files to be included:\n",
						"s3://975050372651-dependencies/dependencies/pydeequ.zip\n"
					]
				}
			],
			"source": [
				"%extra_py_files s3://975050372651-dependencies/dependencies/pydeequ.zip"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Extra jars to be included:\n",
						"s3://975050372651-dependencies/dependencies/deequ-2.0.4-spark-3.3.jar\n",
						"s3://975050372651-dependencies/dependencies/deequ-2.0.4-spark-3.3.jar\n"
					]
				}
			],
			"source": [
				"%extra_jars s3://975050372651-dependencies/dependencies/deequ-2.0.4-spark-3.3.jar"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Current idle_timeout is None minutes.\n",
						"idle_timeout has been set to 2880 minutes.\n",
						"Setting Glue version to: 3.0\n",
						"Previous worker type: None\n",
						"Setting new worker type to: G.1X\n",
						"Previous number of workers: None\n",
						"Setting new number of workers to: 5\n",
						"Trying to create a Glue session for the kernel.\n",
						"Session Type: glueetl\n",
						"Worker Type: G.1X\n",
						"Number of Workers: 5\n",
						"Session ID: 81e3ddf6-ab65-42ee-b316-02fbfe1d1517\n",
						"Applying the following default arguments:\n",
						"--glue_kernel_version 1.0.4\n",
						"--enable-glue-datacatalog true\n",
						"--extra-py-files s3://975050372651-dependencies/dependencies/pydeequ.zip\n",
						"--extra-jars s3://975050372651-dependencies/dependencies/deequ-2.0.4-spark-3.3.jar\n",
						"Waiting for session 81e3ddf6-ab65-42ee-b316-02fbfe1d1517 to get into ready status...\n",
						"Session 81e3ddf6-ab65-42ee-b316-02fbfe1d1517 has been created.\n",
						"\n"
					]
				}
			],
			"source": [
				"%idle_timeout 2880\n",
				"%glue_version 3.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 5\n",
				"\n",
				"import sys\n",
				"import os\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"\n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"os.environ[\"SPARK_VERSION\"]='3.3'"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"from pydeequ.checks import *\n",
				"from pydeequ.verification import *"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 21,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"import os\n",
				"\n",
				"class DataWriter:\n",
				"    def write_parquet(self, df, output_directory, partitioned_by, mode=\"overwrite\"):\n",
				"        df.write.partitionBy(partitioned_by).mode(mode).parquet(output_directory)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"from pyspark.sql.types import StructType, StructField, StringType, StringType, DoubleType, LongType, ArrayType\n",
				"\n",
				"SCHEMA = StructType([\n",
				"    StructField(\"test_keys\", StructType([\n",
				"        StructField(\"accessible\", StringType(), True),\n",
				"        StructField(\"agent\", StringType(), True),\n",
				"        StructField(\"blocking\", StringType(), True),\n",
				"        StructField(\"body_length_match\", StringType(), True),\n",
				"        StructField(\"body_proportion\", DoubleType(), True),\n",
				"        StructField(\"client_resolver\", StringType(), True),\n",
				"        StructField(\"control\", StructType([\n",
				"            StructField(\"dns\", StructType([\n",
				"                StructField(\"addrs\", ArrayType(StringType(), True), True),\n",
				"                StructField(\"failure\", StringType(), True)\n",
				"            ]), True),\n",
				"            StructField(\"http_request\", StructType([\n",
				"                StructField(\"body_length\", LongType(), True),\n",
				"                StructField(\"failure\", StringType(), True),\n",
				"                StructField(\"headers\", StructType([\n",
				"                    StructField(\"Accept-Ranges\", StringType(), True),\n",
				"                    StructField(\"CF-RAY\", StringType(), True),\n",
				"                    StructField(\"Cache-Control\", StringType(), True),\n",
				"                    StructField(\"Content-Language\", StringType(), True),\n",
				"                    StructField(\"Content-Location\", StringType(), True),\n",
				"                    StructField(\"Content-Type\", StringType(), True),\n",
				"                    StructField(\"Date\", StringType(), True),\n",
				"                    StructField(\"ETag\", StringType(), True),\n",
				"                    StructField(\"Expires\", StringType(), True),\n",
				"                    StructField(\"Last-Modified\", StringType(), True),\n",
				"                    StructField(\"Server\", StringType(), True),\n",
				"                    StructField(\"Set-Cookie\", StringType(), True),\n",
				"                    StructField(\"Strict-Transport-Security\", StringType(), True),\n",
				"                    StructField(\"TCN\", StringType(), True),\n",
				"                    StructField(\"Vary\", StringType(), True),\n",
				"                    StructField(\"X-Content-Type-Options\", StringType(), True),\n",
				"                    StructField(\"X-Frame-Options\", StringType(), True),\n",
				"                    StructField(\"X-Xss-Protection\", StringType(), True),\n",
				"                    StructField(\"content-encoding\", StringType(), True)\n",
				"                ]), True),\n",
				"                StructField(\"status_code\", LongType(), True),\n",
				"                StructField(\"title\", StringType(), True)\n",
				"            ]), True)\n",
				"        ]), True),\n",
				"        StructField(\"control_failure\", StringType(), True),\n",
				"        StructField(\"dns_consistency\", StringType(), True),\n",
				"        StructField(\"dns_experiment_failure\", StringType(), True),\n",
				"        StructField(\"headers_match\", StringType(), True),\n",
				"        StructField(\"http_experiment_failure\", StringType(), True),\n",
				"        StructField(\"queries\", ArrayType(StructType([\n",
				"            StructField(\"answers\", ArrayType(StructType([\n",
				"                StructField(\"answer_type\", StringType(), True),\n",
				"                StructField(\"ipv4\", StringType(), True)\n",
				"            ]), True), True),\n",
				"            StructField(\"failure\", StringType(), True),\n",
				"            StructField(\"hostname\", StringType(), True),\n",
				"            StructField(\"query_type\", StringType(), True),\n",
				"            StructField(\"resolver_hostname\", StringType(), True),\n",
				"            StructField(\"resolver_port\", StringType(), True)\n",
				"        ]), True), True),\n",
				"        StructField(\"requests\", ArrayType(StructType([\n",
				"            StructField(\"failure\", StringType(), True),\n",
				"            StructField(\"request\", StructType([\n",
				"                StructField(\"body\", StringType(), True),\n",
				"                StructField(\"headers\", StructType([\n",
				"                    StructField(\"Accept\", StringType(), True),\n",
				"                    StructField(\"Accept-Language\", StringType(), True),\n",
				"                    StructField(\"User-Agent\", StringType(), True)\n",
				"                ]), True),\n",
				"                StructField(\"method\", StringType(), True),\n",
				"                StructField(\"tor\", StructType([\n",
				"                    StructField(\"exit_ip\", StringType(), True),\n",
				"                    StructField(\"exit_name\", StringType(), True),\n",
				"                    StructField(\"is_tor\", StringType(), True)\n",
				"                ]), True),\n",
				"                StructField(\"url\", StringType(), True)\n",
				"            ]), True),\n",
				"            StructField(\"response\", StructType([\n",
				"                StructField(\"body\", StringType(), True),\n",
				"                StructField(\"code\", LongType(), True),\n",
				"                StructField(\"headers\", StructType([\n",
				"                    StructField(\"Accept-Ranges\", StringType(), True),\n",
				"                    StructField(\"Cache-Control\", StringType(), True),\n",
				"                    StructField(\"Content-Language\", StringType(), True),\n",
				"                    StructField(\"Content-Location\", StringType(), True),\n",
				"                    StructField(\"Content-Type\", StringType(), True),\n",
				"                    StructField(\"Date\", StringType(), True),\n",
				"                    StructField(\"ETag\", StringType(), True),\n",
				"                    StructField(\"Expires\", StringType(), True),\n",
				"                    StructField(\"Last-Modified\", StringType(), True),\n",
				"                    StructField(\"Location\", StringType(), True),\n",
				"                    StructField(\"Server\", StringType(), True),\n",
				"                    StructField(\"Strict-Transport-Security\", StringType(), True),\n",
				"                    StructField(\"TCN\", StringType(), True),\n",
				"                    StructField(\"Vary\", StringType(), True),\n",
				"                    StructField(\"X-Content-Type-Options\", StringType(), True),\n",
				"                    StructField(\"X-Frame-Options\", StringType(), True),\n",
				"                    StructField(\"X-Xss-Protection\", StringType(), True),\n",
				"                    StructField(\"content-encoding\", StringType(), True)\n",
				"                ]), True)\n",
				"            ]), True)\n",
				"        ]), True), True),\n",
				"        StructField(\"retries\", LongType(), True),\n",
				"        StructField(\"socksproxy\", StringType(), True),\n",
				"        StructField(\"status_code_match\", StringType(), True),\n",
				"        StructField(\"tcp_connect\", ArrayType(StructType([\n",
				"            StructField(\"ip\", StringType(), True),\n",
				"            StructField(\"port\", LongType(), True),\n",
				"            StructField(\"status\", StructType([\n",
				"                StructField(\"blocked\", StringType(), True),\n",
				"                StructField(\"failure\", StringType(), True),\n",
				"                StructField(\"success\", StringType(), True)\n",
				"            ]), True)\n",
				"        ]), True), True),\n",
				"        StructField(\"title_match\", StringType(), True)\n",
				"    ]), True),\n",
				"    StructField(\"annotations\", StructType([\n",
				"        StructField(\"platform\", StringType(), True)\n",
				"    ]), True),\n",
				"    StructField(\"backend_version\", StringType(), True),\n",
				"    StructField(\"bucket_date\", StringType(), True),\n",
				"    StructField(\"data_format_version\", StringType(), True),\n",
				"    StructField(\"id\", StringType(), True),\n",
				"    StructField(\"input\", StringType(), True),\n",
				"    StructField(\"input_hashes\", ArrayType(StringType(), True), True),\n",
				"    StructField(\"measurement_start_time\", StringType(), True),\n",
				"    StructField(\"options\", ArrayType(StringType(), True), True),\n",
				"    StructField(\"probe_asn\", StringType(), True),\n",
				"    StructField(\"probe_cc\", StringType(), True),\n",
				"    StructField(\"probe_city\", StringType(), True),\n",
				"    StructField(\"probe_ip\", StringType(), True),\n",
				"    StructField(\"report_filename\", StringType(), True),\n",
				"    StructField(\"report_id\", StringType(), True),\n",
				"    StructField(\"software_name\", StringType(), True),\n",
				"    StructField(\"software_version\", StringType(), True),\n",
				"    StructField(\"test_helpers\", StructType([\n",
				"        StructField(\"backend\", StructType([\n",
				"            StructField(\"address\", StringType(), True),\n",
				"            StructField(\"type\", StringType(), True)\n",
				"        ]), True)\n",
				"    ]), True),\n",
				"    StructField(\"test_name\", StringType(), True),\n",
				"    StructField(\"test_runtime\", DoubleType(), True),\n",
				"    StructField(\"test_start_time\", StringType(), True),\n",
				"    StructField(\"test_version\", StringType(), True)\n",
				"])"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"from pyspark.sql import DataFrame\n",
				"\n",
				"class UnsupportedFileType(Exception):\n",
				"    def __init__(self, file_type):\n",
				"        self.file_type = file_type\n",
				"        self.message = f\"File(s) of type {file_type} not supported\"\n",
				"        super().__init__(self.message)\n",
				"\n",
				"class ExtractData:\n",
				"    def __init__(self, spark, file_directory: list, file_type: str):\n",
				"        self.file_directory = file_directory\n",
				"        self.file_type = file_type\n",
				"        self.spark = spark\n",
				"\n",
				"    def extract(self) -> DataFrame:\n",
				"        if self.file_type in ('json'):\n",
				"            return self.spark.read.format(\"json\")\\\n",
				"                .option(\"recursiveFileLookup\", \"true\")\\\n",
				"                .option(\"pathGlobFilter\",\"*.json\")\\\n",
				"            .load(self.file_directory, schema=SCHEMA)\n",
				"        else:\n",
				"            raise UnsupportedFileType(self.file_type)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 17,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"from abc import ABC, abstractmethod\n",
				"import pyspark.sql.functions as F\n",
				"from pyspark.sql.types import *\n",
				"from pyspark.sql import DataFrame\n",
				"from pydeequ.analyzers import *\n",
				"from pydeequ.verification import VerificationSuite\n",
				"import os\n",
				"\n",
				"\n",
				"class TransformData(ABC):\n",
				"    \"\"\"\n",
				"    Gathers general functions for all transformations.\n",
				"    \"\"\"\n",
				"    def load_column_rename_mappings(self, transformation_name):\n",
				"        column_rename_mappings = json_column_rename\n",
				"        return column_rename_mappings.get(transformation_name, {})\n",
				"\n",
				"\n",
				"    def rename_columns(self, df: DataFrame, column_rename) -> DataFrame:\n",
				"        for old_name, new_name in column_rename.items():\n",
				"            df = df.withColumnRenamed(old_name, new_name)\n",
				"        return df\n",
				"\n",
				"    @abstractmethod\n",
				"    def transform(self) -> DataFrame:\n",
				"        pass\n",
				"    \n",
				"    @abstractmethod\n",
				"    def data_quality(self):\n",
				"        pass\n",
				"\n",
				"\n",
				"class Transformation(TransformData):\n",
				"    \"\"\"\n",
				"    Functions for transforming the pandas dataframe for banks.\n",
				"    \"\"\"\n",
				"    def __init__(self, df: DataFrame, spark):\n",
				"        \"\"\"\n",
				"        Receives the dataframe.\n",
				"        \"\"\"\n",
				"        self.df = df\n",
				"        self.spark = spark\n",
				"\n",
				"\n",
				"    def transform(self) -> DataFrame:\n",
				"\n",
				"        transformed_df = self.df.drop(\n",
				"            \"backend_version\"\n",
				"            ,\"input_hashes\"\n",
				"            ,\"probe_city\"\n",
				"            ,\"test_keys.accessible\"\n",
				"            ,\"test_keys.agent\"\n",
				"            \n",
				"        )\n",
				"        \n",
				"        transformed_df = transformed_df.withColumn(\"bucket_date\", F.to_date(F.col(\"bucket_date\")))\\\n",
				"                                       .withColumn(\"measurement_start_time\", F.to_timestamp(\"measurement_start_time\"))\\\n",
				"                                       .withColumn(\"test_start_time\", F.to_timestamp(\"test_start_time\"))\\\n",
				"\n",
				"    \n",
				"        return transformed_df\n",
				"\n",
				"    def data_quality(self, df):\n",
				"\n",
				"        check = Check(self.spark, CheckLevel.Warning, \"Review Check\")\n",
				"        check_result = (VerificationSuite(self.spark)\n",
				"                        .onData(df)\n",
				"                        .addCheck(check\n",
				"                        .hasCompleteness(\"id\", lambda completeness: completeness >= 0.9)\n",
				"                        .hasCompleteness(\"probe_asn\", lambda completeness: completeness >= 0.9)\n",
				"                        .hasCompleteness(\"probe_cc\", lambda completeness: completeness >= 0.98)\n",
				"                        .hasCompleteness(\"probe_ip\", lambda completeness: completeness >= 0.9)\n",
				"                        .hasCompleteness(\"test_start_time\", lambda completeness: completeness >= 0.9)\n",
				"                        .hasCompleteness(\"test_name\", lambda completeness: completeness >= 0.9)\n",
				"                        .hasCompleteness(\"bucket_date\", lambda completeness: completeness >= 0.98)\n",
				"                        .hasCompleteness(\"measurement_start_time\", lambda completeness: completeness >= 0.9)\n",
				"                        .isContainedIn(\"probe_cc\", [\"BR\", \"CN\", \"FR\", \"RU\", \"GB\", \"US\", \"DE\", \"IN\", \"AR\"])\n",
				"                        # .hasCompleteness(\"is_ip_valid\", lambda completeness: completeness >= 0.9)\n",
				"                        # .hasCompleteness(\"is_url_valid\", lambda completeness: completeness >= 0.9)\n",
				"                        .hasSize(lambda size: size > 0))\n",
				"                        .run())\n",
				"        \n",
				"        df_check_result = VerificationResult.checkResultsAsDataFrame(self.spark,check_result)\n",
				"\n",
				"        if len(df_check_result.filter(F.col(\"constraint_status\") != \"Success\").take(1)) != 0:\n",
				"            raise Exception(\"Error Data Quality\")\n",
				"    "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Execution Interrupted. Attempting to cancel the statement (statement_id=27)\n"
					]
				}
			],
			"source": [
				"extract_data = ExtractData(\n",
				"    spark=spark,\n",
				"    file_directory='s3://975050372651-raw/', \n",
				"    file_type='json'\n",
				")\n",
				"df_raw = extract_data.extract()\n",
				"\n",
				"transform_data = Transformation(df_raw, spark)\n",
				"df_ooni = transform_data.transform()\n",
				"\n",
				"transform_data.data_quality(df_ooni)\n",
				"\n",
				"output_directory = 's3://975050372651-trusted/trusted'\n",
				"write_data = DataWriter()\n",
				"write_data.write_parquet(df_ooni, output_directory, ['bucket_date', 'probe_cc'])\n",
				"\n",
				"job.commit()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
